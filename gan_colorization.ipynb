{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the paper -- Our Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Loading Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "paths = glob.glob(\"datasets/test2017/*.jpg\") # COCO 데이터셋의 이미지들\n",
    "np.random.seed(123) # Seeding for reproducible results\n",
    "paths_subset = np.random.choice(paths, 10000, replace=False) # 무작위 10,000개의 이미지를 선택\n",
    "rand_idxs = np.random.permutation(10000) # 선택한 이미지들의 인덱스를 섞는다\n",
    "train_idxs = rand_idxs[:8000] # 80%는 학습 데이터로 사용\n",
    "val_idxs = rand_idxs[8000:] # 20%는 검증 데이터로 사용\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(len(train_paths), len(val_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 = Making Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from colorization_dataset import ColorizationDataset\n",
    "\n",
    "# SIZE = 256\n",
    "# class ColorizationDataset(Dataset):\n",
    "#     def __init__(self, paths, split='train'):\n",
    "#         if split == 'train':\n",
    "#             self.transforms = transforms.Compose([\n",
    "#                 transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
    "#                 transforms.RandomHorizontalFlip(), # A little data augmentation!\n",
    "#             ])\n",
    "#         elif split == 'val':\n",
    "#             self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
    "#\n",
    "#         self.split = split\n",
    "#         self.size = SIZE\n",
    "#         self.paths = paths\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "#         img = self.transforms(img)\n",
    "#         img = np.array(img)\n",
    "#         img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
    "#         img_lab = transforms.ToTensor()(img_lab)\n",
    "#         L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
    "#         ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
    "#\n",
    "#         return {'L': L, 'ab': ab}\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n",
      "500 125\n"
     ]
    }
   ],
   "source": [
    "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs):  # 데이터로더를 생성하는 함수\n",
    "    dataset = ColorizationDataset(**kwargs) # 주어진 매개변수를 이용해 데이터셋을 생성한다.\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                            pin_memory=pin_memory) # 생성한 데이터셋으로 데이터로더를 생성한다.\n",
    "    return dataloader\n",
    "\n",
    "train_dl = make_dataloaders(paths=train_paths, split='train') # 학습 데이터셋에 대한 데이터로더\n",
    "val_dl = make_dataloaders(paths=val_paths, split='val') # 검증 데이터셋에 대한 데이터로더\n",
    "\n",
    "data = next(iter(train_dl)) # 첫 번째 미니배치\n",
    "Ls, abs_ = data['L'], data['ab'] # LAB 이미지의 L과 AB\n",
    "print(Ls.shape, abs_.shape)\n",
    "print(len(train_dl), len(val_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Generator proposed by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net 구조에서 사용되는 각 블록을 정의하는 클래스\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
    "                 innermost=False, outermost=False):\n",
    "        super().__init__()\n",
    "        self.outermost = outermost\n",
    "\n",
    "        # 입력 채널이 지정되지 않았다면 출력 채널(nf)를 사용\n",
    "        if input_c is None: input_c = nf\n",
    "\n",
    "        # 다운샘플링을 위한 Convolution 정의\n",
    "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
    "                             stride=2, padding=1, bias=False)\n",
    "        downrelu = nn.LeakyReLU(0.2, True)\n",
    "        downnorm = nn.BatchNorm2d(ni)\n",
    "        uprelu = nn.ReLU(True)\n",
    "        upnorm = nn.BatchNorm2d(nf)\n",
    "\n",
    "        # outermost일 때는 업샘플링 후 Tanh 활성화 함수를 사용\n",
    "        if outermost:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1)\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "\n",
    "        # innermost일 때는 업샘플링 후 BatchNorm 사용\n",
    "        elif innermost:\n",
    "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "\n",
    "        # 그 외의 경우에는 업샘플링 후 BatchNorm 및 Dropout(optional) 사용\n",
    "        else:\n",
    "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
    "                                        stride=2, padding=1, bias=False)\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            # dropuot인 경우 Dropout 레이어 추가\n",
    "            if dropout: up += [nn.Dropout(0.5)]\n",
    "            model = down + [submodule] + up\n",
    "\n",
    "        # Sequential을 사용ㅇ하여 레이어를 순차적으로 적용\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # outermost일 때는 모델 전체를 반환\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        # 그 외에는 입력과 모델의 결과를 채널 방향으로 결합하여 반환\n",
    "        else:\n",
    "            return torch.cat([x, self.model(x)], 1)\n",
    "\n",
    "# U-Net 아키텍쳐를 정의하는 클래스\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # innermost 레이어를 만들기 위해 UnetBlock 클래스를 사용\n",
    "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
    "\n",
    "        # n_down - 5 만큼의 다운샘플링 레이어를 생성\n",
    "        for _ in range(n_down - 5):\n",
    "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
    "        out_filters = num_filters * 8\n",
    "\n",
    "        # 3개의 업샘플링 레이어를 생성\n",
    "        for _ in range(3):\n",
    "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
    "            out_filters //= 2\n",
    "\n",
    "        # outermost 레이어를 생성하여 전체 U-Net 아키텍쳐 생성\n",
    "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatchGan Discriminator를 정의하는 클래스\n",
    "class PatchDiscriminator(nn.Module):\n",
    "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
    "        super().__init__()\n",
    "\n",
    "        model = [self.get_layers(input_c, num_filters, norm=False)] # Discriminator 모델을 정의하기 위한 리스트\n",
    "\n",
    "        # 다운샘플링 레이어를 추가\n",
    "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
    "                          for i in range(n_down)]\n",
    "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # 마지막 레이어 추가 (Normalization 및 Activation을 사용하지 않음)\n",
    "\n",
    "        self.model = nn.Sequential(*model) # Sequential을 이용하여 Discriminator 모델 정의\n",
    "\n",
    "    # Discriminator에서 사용되는 Convolutional 레이어를 생성하는 메서드\n",
    "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True):\n",
    "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)] # Convolutional 레이어 추가\n",
    "        if norm: layers += [nn.BatchNorm2d(nf)] # Batch Normalization 레이어 추가\n",
    "        if act: layers += [nn.LeakyReLU(0.2, True)] # Leaky ReLU Activation 레이어 추가\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchDiscriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(PatchDiscriminator(input_c=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([16, 1, 30, 30])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = PatchDiscriminator(3) # PatchGAN Discriminator 인스턴스 생성\n",
    "dummy_input = torch.randn(16, 3, 256, 256) # batch_size, channels, size, size (더미 입력 데이터 샘플 16개, 채널 3개, 256x256 크기)\n",
    "out = discriminator(dummy_input) # 모델에 더미 입력을 전달하여 출력 계산\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 - GAN Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN loss을 정의하는 클래스\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        # 실제 및 가짜 레이블을 버퍼로 등록\n",
    "        self.register_buffer('real_label', torch.tensor(real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
    "\n",
    "        # GAN 모드에 따라 loss 함수 선택\n",
    "        if gan_mode == 'vanilla':\n",
    "            self.loss = nn.BCEWithLogitsLoss() # 이진 교차 엔트로피 loss\n",
    "        elif gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss() # 평균 제곱 오차 loss\n",
    "\n",
    "    # 실제 또는 가짜 레이블을 반환하는 메서드\n",
    "    def get_labels(self, preds, target_is_real):\n",
    "        if target_is_real:\n",
    "            labels = self.real_label\n",
    "        else:\n",
    "            labels = self.fake_label\n",
    "        return labels.expand_as(preds)\n",
    "\n",
    "    # GAN loss을 계산하여 반환하는 메서드\n",
    "    def __call__(self, preds, target_is_real):\n",
    "        labels = self.get_labels(preds, target_is_real)\n",
    "        loss = self.loss(preds, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 - Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02):\n",
    "\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.data, 1., gain)\n",
    "            nn.init.constant_(m.bias.data, 0.)\n",
    "\n",
    "    net.apply(init_func)\n",
    "    print(f\"model initialized with {init} initialization\")\n",
    "    return net\n",
    "\n",
    "def init_model(model, device):\n",
    "    model = model.to(device)\n",
    "    model = init_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 - Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized with norm initialization\n",
      "model initialized with norm initialization\n"
     ]
    }
   ],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
    "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
    "        \"\"\"\n",
    "        :param net_G:\n",
    "        :param lr_G: Generator의 학습률\n",
    "        :param lr_D: Discriminator의 학습률\n",
    "        :param beta1: Adam 옵티마이저의 첛 번째 모멘텀\n",
    "        :param beta2: Adam 옵티마이저의 두 번째 모멘텀\n",
    "        :param lambda_L1: L1 loss 가중치\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # macOS M1 프로세스를 사용할 때 GPU를 쓰기 위한 코드\n",
    "        self.device = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "        # lambda_L1은 L1 loss 가중치\n",
    "        self.lambda_L1 = lambda_L1\n",
    "\n",
    "        # Generator 및 Discriminator 모델 초기화\n",
    "        if net_G is None:\n",
    "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
    "        else:\n",
    "            self.net_G = net_G.to(self.device)\n",
    "\n",
    "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
    "\n",
    "        # GAN 및 L1 loss 함수 초기화\n",
    "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
    "        self.L1criterion = nn.L1Loss()\n",
    "\n",
    "        # Generator 및 Discriminator의 최적화를 위한 Adam 옵티마이저 초기화\n",
    "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "\n",
    "    # 모델의 파라미터에 대해 requires_grad를 설정하는 메서드\n",
    "    def set_requires_grad(self, model, requires_grad=True):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "\n",
    "    # 입력 데이터를 설정하는 메서드\n",
    "    def setup_input(self, data):\n",
    "        self.L = data['L'].to(self.device)\n",
    "        self.ab = data['ab'].to(self.device)\n",
    "\n",
    "    def forward(self):\n",
    "        self.fake_color = self.net_G(self.L)\n",
    "\n",
    "    # Discriminator를 역전파하여 loss 계산하는 메서드\n",
    "    def backward_D(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image.detach())\n",
    "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
    "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
    "        real_preds = self.net_D(real_image)\n",
    "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
    "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
    "        self.loss_D.backward()\n",
    "\n",
    "    # Generator를 역전파하여 GAN 및 L1 loss 계산하는 메서드\n",
    "    def backward_G(self):\n",
    "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
    "        fake_preds = self.net_D(fake_image)\n",
    "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
    "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
    "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
    "        self.loss_G.backward()\n",
    "\n",
    "    # 최적화를 수행하는 메서드\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "\n",
    "        # Discriminator 업데이트\n",
    "        self.net_D.train()\n",
    "        self.set_requires_grad(self.net_D, True)\n",
    "        self.opt_D.zero_grad()\n",
    "        self.backward_D()\n",
    "        self.opt_D.step()\n",
    "\n",
    "        # Generator 업데이트\n",
    "        self.net_G.train()\n",
    "        self.set_requires_grad(self.net_D, False)\n",
    "        self.opt_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.opt_G.step()\n",
    "\n",
    "model = MainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 - Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "\n",
    "    def update(self, val, count=1):\n",
    "        # 주어진 값(val)과 개수(count)를 사용하여 미터로 업데이트하는 메서드\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def create_loss_meters():\n",
    "    \"\"\"\n",
    "    여러 loss을 기록하기 위한 AverageMeter 객체들을 생성하는 함수\n",
    "    :return: 각 loss 유형에 대한 AverageMeter 객체를 생성하고 이들을 딕셔너리로 반환\n",
    "    \"\"\"\n",
    "\n",
    "    loss_D_fake = AverageMeter() # 가짜 데이터에 대한 Discriminator loss\n",
    "    loss_D_real = AverageMeter() # 진짜 데이터에 대한 Discriminator loss\n",
    "    loss_D = AverageMeter() # 전체 Discriminator loss\n",
    "    loss_G_GAN = AverageMeter() # Generator GAN loss\n",
    "    loss_G_L1 = AverageMeter() # Generator L1 loss\n",
    "    loss_G = AverageMeter() # 전체 Generator loss\n",
    "\n",
    "    return {'loss_D_fake': loss_D_fake,\n",
    "            'loss_D_real': loss_D_real,\n",
    "            'loss_D': loss_D,\n",
    "            'loss_G_GAN': loss_G_GAN,\n",
    "            'loss_G_L1': loss_G_L1,\n",
    "            'loss_G': loss_G}\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    # 모델의 loss 값을 받아와서 각 loss 유형에 해당하는 AverageMeter를 업데이트 하는 함수\n",
    "    # 주어진 모델에서 각 loss 유형에 대한 loss 값을 가져와서 AverageMeter를 업데이트\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name) # 모델에서 해당 loss 유형에 대한 loss 값을 가져옴\n",
    "        loss_meter.update(loss.item(), count=count) # AverageMeter 업데이트 (count는 배치 크기)\n",
    "\n",
    "def lab_to_rgb(L, ab):\n",
    "    \"\"\"\n",
    "    LAB에서 RGB로 변환하는 함수\n",
    "    :param L: L 채널(명도) 정보를 포함하는 Tensor\n",
    "    :param ab: ab 채널(색상) 정보를 포함하는 Tensor\n",
    "    :return: RGB 이미지로 변환된 Numpy 배열\n",
    "    \"\"\"\n",
    "\n",
    "    # L, AB 채널을 원래 범위로 되돌리고 Tensor를 Numpy 배열로 반환\n",
    "    L = (L + 1.) * 50.\n",
    "    ab = ab * 110.\n",
    "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy() # GPU <-> CPU 변경????????????????\n",
    "\n",
    "    # 각 이미지에 대해서 LAB에서 RGB로 변경\n",
    "    rgb_imgs = []\n",
    "    for img in Lab:\n",
    "        img_rgb = lab2rgb(img)\n",
    "        rgb_imgs.append(img_rgb)\n",
    "    return np.stack(rgb_imgs, axis=0) # Numpy 배열로 스택하여 반환\n",
    "\n",
    "def visualize(model, data, save=True):\n",
    "    \"\"\"\n",
    "    모델의 출력을 시각화하는 함수\n",
    "    :param model: 시각화할 모델\n",
    "    :param data: 시각화할 데이터\n",
    "    :param save: 이미지를 저장할지 여부를 결정하는 플래그\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Generator 네트워크를 평가 모드로 설정하고, 입력 데이터를 이용\n",
    "    model.net_G.eval()\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    model.net_G.train()\n",
    "\n",
    "    # 생성된 가짜 컬러 이미지와 실제 컬러 이미지를 가져옴\n",
    "    fake_color = model.fake_color.detach()\n",
    "    real_color = model.ab\n",
    "    L = model.L\n",
    "\n",
    "    # LAB에서 RGB로 이미지 변환\n",
    "    fake_imgs = lab_to_rgb(L, fake_color)\n",
    "    real_imgs = lab_to_rgb(L, real_color)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 8)) # 시각화를 위한 Matplotlib 플롯 설정\n",
    "\n",
    "    # 첫 5개의 샘플에 대해 각각 원본 L 채널, 생성된 컬러 이미지, 실제 컬러 이미지를 플롯\n",
    "    for i in range(5):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        ax.imshow(L[i][0].cpu(), cmap='gray') # 원본 L 채널\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
    "        ax.imshow(fake_imgs[i]) # 생성된 컬러 이미지\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
    "        ax.imshow(real_imgs[i]) # 실제 컬러 이미지\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if save: # save 플래그가 True인 경우 이미지를 파일로 저장\n",
    "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
    "\n",
    "def log_results(loss_meter_dict): # 로그\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 - Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, epochs, display_every=200):\n",
    "    data = next(iter(val_dl)) # Validation 데이터로부터 시각화용 배치를 얻음\n",
    "\n",
    "    for e in range(epochs):\n",
    "        loss_meter_dict = create_loss_meters() # loss을 기록하기 위한 미터 객체들을 초기화\n",
    "        i = 0 # 반복 횟수\n",
    "        for data in tqdm(train_dl): # 훈련 데이터 로더에서 미니배치를 순회\n",
    "            model.setup_input(data) # 모델 입력 데이터 설정\n",
    "            model.optimize() # 모델 최적화\n",
    "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # loss 업데이트\n",
    "            i += 1\n",
    "            if i % display_every == 0: # 주어진 주기마다 loss과 모델 출력을 표시\n",
    "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
    "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
    "                log_results(loss_meter_dict) # 현재까지의 loss을 출력\n",
    "                visualize(model, data, save=False) # 모델의 출력을 시각화\n",
    "\n",
    "train_model(model, train_dl, 100) # 모델 훈련 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "model = MainModel()\n",
    "\n",
    "# Apple M1\n",
    "device = torch.device(\"mps:0\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"trained_model.pth\",\n",
    "        map_location=device\n",
    "    )\n",
    ")\n",
    "path = \"blackwhite.jpg\"\n",
    "img = PIL.Image.open(path)\n",
    "img = img.resize((256, 256))\n",
    "# to make it between -1 and 1\n",
    "img = transforms.ToTensor()(img)[:1] * 2. - 1.\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model.net_G(img.unsqueeze(0).to(device))\n",
    "colorized = lab_to_rgb(img.unsqueeze(0), preds.cpu())[0]\n",
    "plt.imshow(colorized)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
